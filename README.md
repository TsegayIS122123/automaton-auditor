# ğŸ¤– Automaton Auditor
A multi-agent LangGraph swarm for autonomous code audit and governance. Digital courtroom architecture with parallel detectives and dialectical judges.

<div align="center">
  
![Python](https://img.shields.io/badge/Python-3.10+-blue)
![LangGraph](https://img.shields.io/badge/LangGraph-1.0-green)
![Pydantic](https://img.shields.io/badge/Pydantic-2.0-red)
![Tests](https://img.shields.io/badge/Tests-Passing-brightgreen)
![License](https://img.shields.io/badge/License-MIT-yellow)
![Status](https://img.shields.io/badge/Status-Final_Submission-purple)
  
  **A Multi-Agent System for Autonomous Code Audit & Governance**
  
  *"Digital Courtroom Architecture with Parallel Detectives and Dialectical Judges"*
  
</div>

---

## ğŸ“‹ Table of Contents
- [Overview](#-overview)
- [The Problem](#-the-problem)
- [The Solution](#-the-solution)
- [Architecture Deep Dive](#-architecture-deep-dive)
- [Key Concepts Explained](#-key-concepts-explained)
- [Features](#-features)
- [Installation](#-installation)
- [Environment Setup](#-environment-setup)
- [Running the System](#-running-the-system)
- [Audit Reports](#-audit-reports)
- [Final Submission](#-final-submission)
- [Self-Audit Results](#-self-audit-results)
- [MinMax Feedback Loop](#-minmax-feedback-loop)
- [Testing](#-testing)
- [Project Structure](#-project-structure)
- [LangSmith Observability](#-langsmith-observability)
- [Video Demonstration](#-video-demonstration)
- [Troubleshooting](#-troubleshooting)
- [License](#-license)
- [Author](#-author)

---

## ğŸ“‹ Overview

The Automaton Auditor is a production-grade **multi-agent system** built with LangGraph that autonomously audits GitHub repositories against complex rubrics. It implements a hierarchical "digital courtroom" architecture where specialized agents collaborate to produce forensic-grade audit reports.

This system addresses the scaling challenge in AI-Native Enterprises: **when 1000 agents generate code simultaneously, humans cannot manually review every PR**. The Automaton Auditor provides automated quality assurance at scale.
## ğŸ¯ The Problem

In a mature AI-Native Enterprise, the volume of code generated by autonomous agents will outpace human review capacity by orders of magnitude. If 1,000 agents are generating features concurrently, humans cannot manually review every pull request. The bottleneck shifts from **generating code** to **evaluating it**.

**Key Challenges:**
- Manual code review doesn't scale
- Human reviewers become bottlenecks
- Quality assurance needs automation
- Subjective judgments need standardization

---

## ğŸ’¡ The Solution

The Automaton Auditor provides automated quality assurance at scale through a swarm of specialized agents:

| Layer | Role | Function |
|-------|------|----------|
| **Detectives** | Evidence Collection | Gather objective facts from code and documentation |
| **Judges** | Dialectical Debate | Apply rubric with conflicting perspectives |
| **Chief Justice** | Final Synthesis | Resolve conflicts with deterministic rules |

This creates a system capable of:
- ğŸ” **Forensic Analysis**: Objectively verifying code artifacts
- âš–ï¸ **Nuanced Judgment**: Applying complex rubrics that require interpretation
- ğŸ“ **Constructive Feedback**: Providing actionable remediation steps

---
## ğŸ›ï¸ Architecture: The Digital Courtroom

```mermaid
graph TB
    subgraph Input["ğŸ“¥ Input Layer"]
        A[GitHub Repository URL] --> Parser
        B[PDF Report] --> Parser
    end

    subgraph Detectives["ğŸ” Detective Layer (Parallel Investigation)"]
        direction TB
        RI[RepoInvestigator<br/>Git + AST Analysis] --> EviAgg
        DA[DocAnalyst<br/>PDF + RAG Analysis] --> EviAgg
        VI[VisionInspector<br/>Diagram Analysis] --> EviAgg
    end

    subgraph Evidence["ğŸ“Š Evidence Aggregation"]
        EviAgg[Evidence Aggregator<br/>Synchronization Node] --> EvidenceStore[(Evidence Store)]
    end

    subgraph Judges["âš–ï¸ Judicial Layer (Dialectical Debate)"]
        direction TB
        EvidenceStore --> Prosecutor
        EvidenceStore --> Defense
        EvidenceStore --> TechLead
        
        Prosecutor[Prosecutor<br/>Critical Lens] --> OpinionPool
        Defense[Defense<br/>Optimistic Lens] --> OpinionPool
        TechLead[Tech Lead<br/>Pragmatic Lens] --> OpinionPool
    end

    subgraph Synthesis["ğŸ›ï¸ Supreme Court"]
        OpinionPool --> ChiefJustice[Chief Justice<br/>Synthesis Engine]
        ChiefJustice --> Rules{Deterministic Rules}
        Rules --> Security[Security Override]
        Rules --> Fact[Fact Supremacy]
        Rules --> Function[Functionality Weight]
        Rules --> Dissent[Dissent Requirement]
    end

    subgraph Output["ğŸ“„ Output Layer"]
        Synthesis --> Report[Audit Report<br/>Markdown]
        Report --> Executive[Executive Summary]
        Report --> Criteria[Criterion Breakdown]
        Report --> Remediation[Remediation Plan]
    end

    Parser --> Detectives
```

### ğŸ”„ Parallel Execution Flow

The architecture implements **two layers of parallel processing**:

| Layer | Components | Pattern |
|-------|------------|---------|
| **Detective Layer** | RepoInvestigator, DocAnalyst, VisionInspector | Fan-out â†’ Aggregate |
| **Judicial Layer** | Prosecutor, Defense, TechLead | Fan-out â†’ Synthesize |

### âš–ï¸ Dialectical Synthesis 

```mermaid
graph LR
    subgraph Thesis["Thesis (Prosecutor)"]
        A[Find Flaws<br/>Score: 1-2] --> Conflict
    end
    
    subgraph Antithesis["Antithesis (Defense)"]
        B[Find Merit<br/>Score: 4-5] --> Conflict
    end
    
    subgraph Conflict["Dialectical Conflict"]
        C{Score Variance > 2?}
    end
    
    subgraph Synthesis["Synthesis (Chief Justice)"]
        C -->|Yes| D[Trigger Dissent]
        C -->|No| E[Apply Rules]
        D --> F[Security Override]
        D --> G[Fact Supremacy]
        D --> H[Functionality Weight]
        E --> F
        E --> G
        E --> H
        F & G & H --> I[Final Verdict]
    end
```

---

## ğŸ¯ Key Features

### ğŸ” Forensic Detective Layer
- **RepoInvestigator**: AST-based code analysis (not regex) with git history forensics
- **DocAnalyst**: PDF parsing with RAG-lite architecture for targeted queries
- **VisionInspector**: Multimodal diagram analysis (optional but implemented)

### âš–ï¸ Dialectical Judicial Layer
- **Prosecutor**: Adversarial lens - finds flaws, gaps, and security issues
- **Defense**: Optimistic lens - rewards effort and creative solutions  
- **Tech Lead**: Pragmatic lens - evaluates maintainability and viability

### ğŸ›ï¸ Supreme Court Synthesis
- **Deterministic conflict resolution** (not LLM averaging)
- **Security override rules** - vulnerabilities cap scores
- **Fact supremacy** - evidence overrides opinion
- **Dissent requirement** - explains score variance

### ğŸ›¡ï¸ Production-Grade Infrastructure
- **Pydantic validation** throughout
- **State reducers** (`operator.add`, `operator.ior`) for parallel safety
- **Sandboxed execution** with tempfile isolation
- **LangSmith observability** for full traceability
- **uv package management** for dependency isolation

---
# ğŸ“‚ Project Structure
```bash
automaton-auditor/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ state.py                 # Pydantic models with reducers
â”‚   â”œâ”€â”€ graph.py                  # LangGraph state machine
â”‚   â”œâ”€â”€ nodes/
â”‚   â”‚   â”œâ”€â”€ detectives.py         # Forensic collectors
â”‚   â”‚   â”œâ”€â”€ judges.py              # Three judicial personas
â”‚   â”‚   â””â”€â”€ justice.py             # Chief Justice synthesis
â”‚   â””â”€â”€ tools/
â”‚       â”œâ”€â”€ repo_tools.py          # Git + AST analysis
â”‚       â””â”€â”€ doc_tools.py           # PDF parsing + RAG
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_detectives.py
â”‚   â”œâ”€â”€ test_judges.py
â”‚   â””â”€â”€ test_synthesis.py
â”œâ”€â”€ audits/
â”‚   â”œâ”€â”€ report_onself_generated/   #  my agent vs my repo
â”‚   â”œâ”€â”€ report_onpeer_generated/    # my agent vs peer repo
â”‚   â””â”€â”€ report_bypeer_received/     # Peer agent vs my repo
â”œâ”€â”€ .env.example                    # API key template
â”œâ”€â”€ pyproject.toml                  # uv dependencies
â”œâ”€â”€ README.md                       # This file
â””â”€â”€ Dockerfile                      # Optional container
```

# ğŸš€ Automaton Auditor 

##  Completed Features

### State Management
-  Pydantic models with `operator.add`/`operator.ior` reducers
-  Evidence, JudicialOpinion, AuditReport schemas
-  Type-safe parallel execution

### Forensic Tools
-  Sandboxed git clone with `tempfile`
-  AST parsing for graph structure detection
-  Git history analysis for commit progression
-  PDF text extraction and chunking
-  RAG-lite with ChromaDB for targeted queries

### Detective Layer
-  RepoInvestigator node (parallel)
-  DocAnalyst node (parallel)
-  EvidenceAggregator for synchronization

### Graph Architecture
-  Fan-out: START â†’ [Repo, Doc]
-  Fan-in: [Repo, Doc] â†’ Aggregator
-  State reducers prevent overwrites
## ğŸš€ Quick Start

### Prerequisites
```bash
# Install uv (fast Python package manager)
curl -LsSf https://astral.sh/uv/install.sh | sh

# Python 3.10+
python --version
```
# Installation
```bash
# Clone repository
git clone https://github.com/TsegayIS122123/automaton-auditor.git
cd automaton-auditor

# Create virtual environment and install dependencies
uv venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate
uv pip install -e .

# Set up environment variables
cp .env.example .env
# Edit .env with your API keys
```
## ğŸš€ Running the Detective Graph

### How to Run It
The detective graph can be executed in three ways:
- **Python script** - Create a `.py` file with the run command
- **One-liner** - Quick test via command line
- **Interactive Python** - Run step-by-step in Python shell

All methods require two parameters:
1. A GitHub repository URL (public repository)
2. A PDF report path (your interim report)

### How to Pass a Target GitHub Repository URL
Pass the URL directly as a string parameter:
- Your own repo: `https://github.com/YOUR_USERNAME/automaton-auditor`
- Peer's repo: `https://github.com/PEER_USERNAME/their-repository`
- Any public repo: `https://github.com/org/repository`

The URL must be a valid, publicly accessible GitHub repository.

### What Output to Expect
The system produces:
- **Console output**: Real-time logging of evidence collection
- **Evidence summary**: Count of items found by each detective
- **Detailed evidence**: For each piece of evidence, you'll see:
  - Goal (what was being checked)
  - Found status (True/False)
  - Confidence score (0-1)
  - Location (file path, commit hash, or page number)
  - Content (relevant code snippets or text)

### Example Execution
Run against any public repository with your PDF report. The system will:
1. Clone the repository in a sandboxed temporary directory
2. Analyze git commit history for progression patterns
3. Parse Python files using AST to detect graph structure
4. Extract and chunk text from the PDF report
5. Query for key concepts like "Dialectical Synthesis"
6. Aggregate all evidence into a structured format

### Output Example
Successful execution shows:
- Evidence aggregator summary with item counts per detective
- For each evidence item: goal, found status, confidence, location
- Total evidence collected across all sources
- Any warnings or errors encountered during execution

### Testing
Run the provided test suite to verify everything works:
- State model tests validate Pydantic schemas and reducers
- Tool tests confirm sandboxing and AST parsing
- Graph tests verify parallel structure compiles
All tests should pass with clear success messages.

### Observability with LangSmith
If LangSmith API keys are configured:
- Every graph execution is traced
- View parallel execution flow in LangSmith dashboard
- Inspect each node's inputs and outputs
- Debug issues with full visibility into the agent's reasoning
Traces appear automatically at https://smith.langchain.com

### Troubleshooting

**Git clone fails**
- Verify the repository URL is public and accessible
- Check internet connection
- For private repos, add GITHUB_TOKEN to .env file

**PDF not found**
- Ensure PDF path is correct relative to project root
- Verify file exists in the reports/ directory
- Check file permissions

**No evidence collected**
- The repository may not contain expected patterns
- PDF may not mention required concepts
- This is normal - evidence.found will be False

**Import errors**
- Run from project root directory
- Install with `uv pip install -e .`
- Activate virtual environment first

**Tests fail**
- Ensure all dependencies installed
- Check Python version (3.10+ required)
- Run `uv pip install -e .` to reinstall
### ğŸ”’ Reproducible Builds

This project uses `uv.lock` for **fully locked dependencies**:

```bash
# Install exact versions from lock file
uv sync

# This guarantees everyone gets IDENTICAL dependencies
```
## ğŸ“¦ **Dependency Management**
This project uses **`uv`** for dependency management:

```bash
# Install dependencies (uses pyproject.toml + uv.lock)
uv sync

# This installs EXACT versions from uv.lock
# NOT requirements.txt (which is deprecated )
```
## ğŸƒâ€â™‚ï¸ Explicit Run Commands

### Using the Python script 
```bash
# After installation, run with ONE command:
python run.py https://github.com/langchain-ai/langgraph reports/interim_report.pdf
```
## ğŸ“Š Expected Output

When you run the detective graph successfully, you should see output like this:

```bash
$ python run.py https://github.com/langchain-ai/langgraph reports/interim_report.pdf

ğŸš€ Automaton Auditor - Detective Phase
ğŸ“¦ Repository: https://github.com/langchain-ai/langgraph
ğŸ“„ PDF Report: reports/interim_report.pdf
--------------------------------------------------

ğŸ“Š Evidence Aggregator: Collected 8 evidence items
   - doc: 7 items
   - repo: 1 items
ğŸ“Š Evidence Check: 8 items collected

âœ… Done! Collected 8 evidence items
```
# Automaton Auditor - Final Audit Report

**Generated:** 2026-02-27 15:30:00
**Repository:** https://github.com/user/repo

## Executive Summary
**Overall Score: 4.2/5**

### Strengths
-  Git Forensic Analysis
- State Management Rigor

### Areas for Improvement
- âš ï¸ Judicial Nuance
- âš ï¸ Chief Justice Synthesis

## Criterion Breakdown

### 1. Git Forensic Analysis
**Final Score: 5/5**

**The Debate:**
- **Prosecutor**: Found 14 commits showing clear progression (Score: 4)
- **Defense**: Excellent iterative development visible (Score: 5)
- **Tech Lead**: Commit history tells a clear story (Score: 5)

**Remediation:** No issues found.

### 2. Judicial Nuance
**Final Score: 3/5**

**The Debate:**
- **Prosecutor**: Personas not sufficiently distinct (Score: 2)
- **Defense**: Good attempt at role separation (Score: 4)
- **Tech Lead**: Needs more adversarial prompting (Score: 3)

**Dissent:** Disagreement: Prosecutor=2, Defense=4, Tech=3

**Remediation:** Enhance judge prompts to ensure >50% difference between personas.

## Remediation Plan
### Judicial Nuance
Enhance judge prompts to ensure >50% difference between personas. Add more adversarial language to Prosecutor.

### ğŸ† Complete Implementation
-  **Detective Layer**: RepoInvestigator, DocAnalyst, VisionInspector (parallel)
-  **Judicial Layer**: Prosecutor, Defense, TechLead (parallel with structured output)
-  **Supreme Court**: Chief Justice with deterministic synthesis rules
-  **Graph Architecture**: Full parallel fan-out/fan-in with error handling
-  **Infrastructure**: uv.lock, .env.example, comprehensive README

### Audit Reports
- [Self-Audit Report](./audit/report_onself_generated/)
- [Peer-Audit Report](./audit/report_onpeer_generated/)
- [Feedback Received](./audit/report_bypeer_received/)

### Demo & Observability
- ğŸ“¹ [Video Demonstration](./docs/demo.mp4)
- ğŸ”— [LangSmith Trace](https://smith.langchain.com/public/your-trace-link)
- ğŸ“„ [Final Report PDF](./reports/final_report.pdf)

### MinMax Feedback Loop
- **What peer's agent caught**: [describe]
- **How I improved**: [describe]
- **Agent now detects**: [describe]

## âœ… What I Built

### 1. Detective Layer (Fully Implemented)
| Component | Status | Description |
|-----------|--------|-------------|
| **RepoInvestigator** | âœ… Complete | AST-based code analysis, git history forensics, sandboxed cloning |
| **DocAnalyst** | âœ… Complete | PDF chunking, RAG-lite, concept depth analysis |
| **VisionInspector** | âœ… Complete | Diagram detection, image extraction from PDFs |
| **Evidence Aggregator** | âœ… Complete | Synchronization node with fan-in pattern |

### 2. Judicial Layer (Fully Implemented)
| Judge | Philosophy | Scoring Strategy |
|-------|------------|------------------|
| **Prosecutor** | "Trust No One" | Adversarial, finds flaws and security issues |
| **Defense** | "Reward Effort" | Optimistic, rewards creative solutions |
| **Tech Lead** | "Does it work?" | Pragmatic, assesses maintainability |

### 3. Chief Justice (Fully Implemented)
| Rule | Implementation |
|------|----------------|
| **Security Override** | Security flaws cap score at 3 |
| **Fact Supremacy** | Evidence overrules unsupported claims |
| **Functionality Weight** | Tech Lead highest for architecture |
| **Dissent Requirement** | Explains variance > 2 |

### 4. Graph Architecture
- âœ… Two parallel fan-out/fan-in patterns (detectives + judges)
- âœ… Conditional edges for error handling
- âœ… Full end-to-end flow: URL â†’ Detectives â†’ Aggregator â†’ Judges â†’ Synthesis â†’ Report

---

## ğŸ“Š Audit Reports Generated

| Report | Location | Result |
|--------|----------|--------|
| **Self-Audit** | [`audit/report_onself_generated/self_audit.md`](./audit/report_onself_generated/self_audit.md) | Overall Score: 2.9/5 |
| **Peer-Audit** | [`audit/report_onpeer_generated/peer_audit.md`](./audit/report_onpeer_generated/peer_audit.md) | Overall Score: 3.0/5 |
| **Feedback Received** | [`audit/report_bypeer_received/feedback.md`](./audit/report_bypeer_received/feedback.md) | Peer review feedback |

### Self-Audit Highlights
- âœ… 13 evidence items collected across all detectives
- âœ… 60 judicial opinions generated
- âœ… Deterministic synthesis applied all rules
- âœ… Final report saved as Markdown

---

## ğŸ”„ MinMax Feedback Loop

### What I Learned from Peer Review
- Added explicit run commands for better usability
- Enhanced error handling in graph conditional edges
- Improved PDF path validation

### How I Improved My Agent
- Implemented rule-based fallbacks when API unavailable
- Added comprehensive error messages
- Enhanced evidence collection with dimension_id tracking

---

## ğŸš€ Quick Start

```bash
# Install dependencies
uv sync

# Run self-audit
python run.py https://github.com/TsegayIS122123/automaton-auditor reports/interim_report.pdf

# Run peer-audit
python run.py https://github.com/Atnabon/automaton-auditor-swarm reports/interim_report.pdf
```
## ğŸ‘¤ Author

**Tsegay Assefa**
- ğŸ§  AI Systems Architect | Multi-Agent Governance Research
- ğŸ“§ Email: [tsegayassefa27@gmail.com]  
- ğŸ”— GitHub: [@TsegayIS122123](https://github.com/TsegayIS122123)
- ğŸ’¼ LinkedIn: [tsegay-assefa-95a397336](https://www.linkedin.com/in/tsegay-assefa-95a397336/)

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

